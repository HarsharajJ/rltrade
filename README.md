# SPY Options Trading Bot - Reinforcement Learning System

An AI-powered options trading signal generator using **Proximal Policy Optimization (PPO)** reinforcement learning, with cloud database storage for continuous model improvement.

---

## Table of Contents

1. [How It Works](#how-it-works)
2. [Reinforcement Learning Explained](#reinforcement-learning-explained)
3. [Project Architecture](#project-architecture)
4. [Setup & Installation](#setup--installation)
5. [Running the System](#running-the-system)
6. [The Learning Loop](#the-learning-loop)
7. [File Reference](#file-reference)
8. [Technical Details](#technical-details)

---

## How It Works

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        TRADING SIGNAL PIPELINE                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ   [Market Data]  ‚Üí  [Feature Engineering]  ‚Üí  [PPO Model]  ‚Üí  [Signal]
‚îÇ        ‚Üì                    ‚Üì                      ‚Üì              ‚Üì
‚îÇ   SPY + VIX          15 Features            7 Actions        Trade Setup
‚îÇ   prices            IV Rank, RSI,          Call, Put,       Entry, Stop,
‚îÇ                     MACD, etc.             Spreads          Target
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### The Process:

1. **Fetch Data**: Get SPY price, VIX (volatility), and real options data
2. **Build Features**: Calculate 15 technical indicators
3. **AI Decision**: PPO model outputs action probabilities
4. **Generate Signal**: Create trade setup with entry/exit levels
5. **Store to DB**: Save signal for outcome tracking
6. **Track Outcome**: Later check if signal was profitable
7. **Retrain**: Use outcomes to improve the model

---

## Reinforcement Learning Explained

### What is PPO?

**Proximal Policy Optimization (PPO)** is a reinforcement learning algorithm that learns by:

1. **Observing** the market state (15-dimensional feature vector)
2. **Taking actions** (buy call, buy put, spread, hold, close)
3. **Receiving rewards** (profit = positive, loss = negative)
4. **Updating policy** to maximize future rewards

### The RL Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    REINFORCEMENT LEARNING SETUP                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ   AGENT (PPO Model)                                                   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Neural Network with 2 hidden layers (64 neurons each)          ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ   ENVIRONMENT (ProductionOptionsEnv)                                  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Simulates options trading with:                                 ‚îÇ
‚îÇ       ‚Ä¢ Real market data (SPY + VIX)                                  ‚îÇ
‚îÇ       ‚Ä¢ Transaction costs (commission, slippage, spread)              ‚îÇ
‚îÇ       ‚Ä¢ Position management                                           ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ   STATE (15 dimensions)                                               ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ [Price, RSI, MACD, IV, IV_Rank, PCR, Volume, Gamma,            ‚îÇ
‚îÇ        Momentum, Balance, HasPosition, PositionType, PnL, Time]       ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ   ACTIONS (7 choices)                                                 ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ 0: BUY_CALL      (bullish, unlimited profit)                    ‚îÇ
‚îÇ       1: BUY_PUT       (bearish, unlimited profit)                    ‚îÇ
‚îÇ       2: BULL_SPREAD   (bullish, defined risk)                        ‚îÇ
‚îÇ       3: BEAR_SPREAD   (bearish, defined risk)                        ‚îÇ
‚îÇ       4: IRON_CONDOR   (neutral, defined risk)                        ‚îÇ
‚îÇ       5: HOLD          (no action)                                    ‚îÇ
‚îÇ       6: CLOSE         (exit position)                                ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ   REWARD                                                              ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Realized P&L - Transaction Costs - Time Decay Penalty          ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### How Learning Works

```
Episode 1: Agent explores randomly, makes mistakes, learns basic patterns
Episode 100: Agent learns to avoid holding too long (time decay hurts)
Episode 1000: Agent learns bullish signals in uptrends
Episode 10000: Agent develops nuanced strategy based on IV and momentum
```

---

## Project Architecture

```
rltrade/
‚îÇ
‚îú‚îÄ‚îÄ live_signals_production.py   # üéØ Main entry point - generates signals
‚îú‚îÄ‚îÄ train_production.py          # üèãÔ∏è Train the PPO model
‚îú‚îÄ‚îÄ track_outcomes.py            # üìä Track if signals were profitable
‚îú‚îÄ‚îÄ retrain_from_db.py           # üîÑ Retrain using trade history
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database.py              # ‚òÅÔ∏è Neon DB - stores signals/trades
‚îÇ   ‚îú‚îÄ‚îÄ env_production.py        # üéÆ RL Environment (7 actions)
‚îÇ   ‚îú‚îÄ‚îÄ features.py              # üìà Feature engineering (15 dims)
‚îÇ   ‚îú‚îÄ‚îÄ options_data.py          # üìä Real options chain data
‚îÇ   ‚îú‚îÄ‚îÄ options_pricing.py       # üßÆ Black-Scholes + Greeks
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py           # üì• SPY + VIX data fetching
‚îÇ   ‚îî‚îÄ‚îÄ walk_forward.py          # ‚úÖ Rolling validation
‚îÇ
‚îú‚îÄ‚îÄ models/                      # üíæ Saved trained models
‚îÇ   ‚îú‚îÄ‚îÄ ppo_spy_options.zip      # Basic 10-dim model
‚îÇ   ‚îî‚îÄ‚îÄ ppo_retrained.zip        # Production 15-dim model
‚îÇ
‚îî‚îÄ‚îÄ .env                         # üîê API keys and DB credentials
```

---

## Setup & Installation

### Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) package manager
- Neon DB account (free): https://neon.tech

### Step 1: Install Dependencies

```bash
cd rltrade
uv sync
```

### Step 2: Configure Environment

Create `.env` file:

```bash
# Neon DB (required) - get from https://console.neon.tech
DATABASE_URL=postgresql://user:password@ep-xxx.neon.tech/neondb?sslmode=require

# Alpaca (optional - for future live trading)
ALPACA_API_KEY=your_key
ALPACA_SECRET_KEY=your_secret
```

### Step 3: Initialize Database

```bash
uv run python -m src.database --init
```

This creates 4 tables:
- `signals` - AI-generated trading signals
- `trades` - Executed trades with outcomes
- `market_data` - Historical OHLCV data
- `model_versions` - Model performance tracking

---

## Running the System

### 1. Generate Trading Signals

```bash
# Single signal
uv run python live_signals_production.py --once

# Continuous (every 5 minutes)
uv run python live_signals_production.py

# Custom interval (every 1 minute)
uv run python live_signals_production.py --interval 60
```

**Output:**
```
>>> SPY OPTIONS SIGNAL <<<
Time: 2026-01-06T17:27:15

MARKET DATA
   SPY Price:     $687.72
   IV:            20.0%
   RSI:           58.7

AI RECOMMENDATION
   Signal:        [v] BEAR SPREAD
   Confidence:    70.4%

>>> OPTION CONTRACT <<<
   SYMBOL:     SPY 260113 P 688/683
   Type:       BEAR PUT SPREAD

>>> DEFINED RISK <<<
   [MAX PROFIT] $300.00
   [MAX LOSS]   $200.00

Signal stored in DB (id=2)
```

### 2. View Database Contents

```bash
# View all signals and trades
uv run python -m src.database --view

# View statistics
uv run python -m src.database --stats

# View only signals
uv run python -m src.database --signals
```

### 3. Track Trade Outcomes

After time passes, check if signals were profitable:

```bash
# Check signals from last 24 hours
uv run python track_outcomes.py --hours 24

# Run continuously (check every hour)
uv run python track_outcomes.py --continuous --interval 60
```

**How it determines profit/loss:**

| Signal Type | SPY Moves | Result |
|-------------|-----------|--------|
| BULL SPREAD | UP +1%+ | ‚úÖ Profitable |
| BULL SPREAD | DOWN -0.8%+ | ‚ùå Loss |
| BEAR SPREAD | DOWN -1%+ | ‚úÖ Profitable |
| BEAR SPREAD | UP +0.8%+ | ‚ùå Loss |

### 4. Train the Model

```bash
# Quick training (test)
uv run python train_production.py --timesteps 50000 --seeds 1

# Full production training (2-3 hours)
uv run python train_production.py --timesteps 500000 --seeds 3

# Retrain using database feedback
uv run python retrain_from_db.py --timesteps 100000
```

### 5. Walk-Forward Validation

Test model on unseen data with rolling windows:

```bash
uv run python -m src.walk_forward --years 3 --timesteps 100000
```

---

## The Learning Loop

This is the key to continuous improvement:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CONTINUOUS IMPROVEMENT LOOP                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ   1. GENERATE SIGNALS                                                 ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ live_signals_production.py --once                            ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Signal stored in Neon DB with state vector                   ‚îÇ
‚îÇ                              ‚Üì                                        ‚îÇ
‚îÇ   2. WAIT FOR MARKET MOVEMENT                                         ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ SPY price changes over hours/days                            ‚îÇ
‚îÇ                              ‚Üì                                        ‚îÇ
‚îÇ   3. TRACK OUTCOMES                                                   ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ track_outcomes.py --hours 24                                 ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Compares prediction vs reality                               ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Records was_profitable = True/False                          ‚îÇ
‚îÇ                              ‚Üì                                        ‚îÇ
‚îÇ   4. RETRAIN MODEL                                                    ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ retrain_from_db.py --timesteps 100000                        ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Uses profitable signals as positive reward                   ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Uses losing signals as negative reward                       ‚îÇ
‚îÇ                              ‚Üì                                        ‚îÇ
‚îÇ   5. IMPROVED MODEL                                                   ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ New model saved as ppo_retrained.zip                         ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Better predictions over time                                 ‚îÇ
‚îÇ                              ‚Üì                                        ‚îÇ
‚îÇ      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ REPEAT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                             ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Automated Daily Workflow

```bash
# Morning: Generate signal
uv run python live_signals_production.py --once

# Evening: Track today's outcome
uv run python track_outcomes.py --hours 12

# Weekly: Retrain with new data
uv run python retrain_from_db.py --timesteps 100000

# View performance
uv run python -m src.database --stats
```

---

## File Reference

### Main Scripts

| File | Purpose | Command |
|------|---------|---------|
| `live_signals_production.py` | Generate trading signals | `--once`, `--interval 60` |
| `train_production.py` | Train PPO model | `--timesteps 500000 --seeds 3` |
| `track_outcomes.py` | Track signal outcomes | `--hours 24`, `--continuous` |
| `retrain_from_db.py` | Retrain from history | `--timesteps 100000` |

### Source Modules

| File | Purpose |
|------|---------|
| `src/database.py` | Neon DB connection, CRUD operations |
| `src/env_production.py` | RL environment with 7 actions, 15-dim state |
| `src/features.py` | Technical indicators, feature normalization |
| `src/options_data.py` | Fetch real options chains from yfinance |
| `src/options_pricing.py` | Black-Scholes, Greeks calculation |
| `src/data_loader.py` | Download SPY + VIX historical data |
| `src/walk_forward.py` | Rolling window validation |

---

## Technical Details

### State Vector (15 Dimensions)

| Index | Feature | Range | Source |
|-------|---------|-------|--------|
| 0 | SPY Price (normalized) | 0-1 | yfinance |
| 1 | RSI (14-period) | 0-1 | Calculated |
| 2 | MACD Histogram | 0-1 | Calculated |
| 3 | Implied Volatility | 0-1 | VIX proxy |
| 4 | IV Rank (52-week) | 0-1 | Calculated |
| 5 | Put/Call Ratio | 0-1 | Volume-based |
| 6 | Volume Surge | 0-1 | vs 20-day avg |
| 7 | IV Skew | 0-1 | Put-Call IV diff |
| 8 | Gamma Proxy | 0-1 | Strike distance |
| 9 | Momentum (5-day) | 0-1 | Price change |
| 10 | Portfolio Balance | 0-1 | Normalized |
| 11 | Has Position | 0/1 | Binary |
| 12 | Position Type | 0-1 | Encoded |
| 13 | Unrealized P&L | 0-1 | Normalized |
| 14 | Holding Time | 0-1 | Days/max_days |

### Transaction Costs

Built into the environment for realistic training:

```python
COMMISSION = $0.65 per contract per leg
SLIPPAGE = 2% of option premium
BID_ASK_SPREAD = $0.05 per contract
```

### Reward Function

```python
reward = realized_pnl 
       - transaction_costs 
       - time_decay_penalty 
       - invalid_action_penalty
```

---

## Disclaimer

> ‚ö†Ô∏è **RISK WARNING**: Options trading involves substantial risk of loss. This system is for **educational purposes only**. Past performance does not guarantee future results. Always paper trade extensively before using real money.

---

## License

MIT License - Use at your own risk.
#   r l t r a d e  
 